{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Добавление необходимых путей и импорт библиотек."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "root_path = os.getcwd()\n",
    "sys.path.append(os.path.join(root_path,'compressai'))\n",
    "#sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from compressai.zoo import mbt2018_mean\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### В качетсве данных была выбрана поcледовательность пяти кадров из датасета SINTEL (взяты из директории demo-frames из репозитория RAFT), изображения приводим к размеру (H, W) = (512, 1024)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame_0021.png resized and saved to images\\orig_resize_frames\n",
      "frame_0022.png resized and saved to images\\orig_resize_frames\n",
      "frame_0023.png resized and saved to images\\orig_resize_frames\n",
      "frame_0024.png resized and saved to images\\orig_resize_frames\n",
      "frame_0025.png resized and saved to images\\orig_resize_frames\n"
     ]
    }
   ],
   "source": [
    "orig_folder = 'images\\\\demo-frames'\n",
    "orig_resize_folder = 'images\\\\orig_resize_frames'\n",
    "reconstr_folder = 'images\\\\reconstr_frames'\n",
    "\n",
    "resize_transform = transforms.Resize((512, 1024))\n",
    "\n",
    "\n",
    "for filename in os.listdir(orig_folder):\n",
    "    file_path = os.path.join(orig_folder, filename)\n",
    "    img = Image.open(file_path).convert('RGB')  \n",
    "\n",
    "    # Применение трансформации\n",
    "    resized_img = resize_transform(img)\n",
    "\n",
    "    \n",
    "    output_path = os.path.join(orig_resize_folder, filename)\n",
    "    resized_img.save(output_path)\n",
    "\n",
    "    print(f'{filename} resized and saved to {orig_resize_folder}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка предобученной модели mbt2018-mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MeanScaleHyperprior(\n",
       "  (entropy_bottleneck): EntropyBottleneck(\n",
       "    (likelihood_lower_bound): LowerBound()\n",
       "  )\n",
       "  (g_a): Sequential(\n",
       "    (0): Conv2d(3, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "    (1): GDN(\n",
       "      (beta_reparam): NonNegativeParametrizer(\n",
       "        (lower_bound): LowerBound()\n",
       "      )\n",
       "      (gamma_reparam): NonNegativeParametrizer(\n",
       "        (lower_bound): LowerBound()\n",
       "      )\n",
       "    )\n",
       "    (2): Conv2d(128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "    (3): GDN(\n",
       "      (beta_reparam): NonNegativeParametrizer(\n",
       "        (lower_bound): LowerBound()\n",
       "      )\n",
       "      (gamma_reparam): NonNegativeParametrizer(\n",
       "        (lower_bound): LowerBound()\n",
       "      )\n",
       "    )\n",
       "    (4): Conv2d(128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "    (5): GDN(\n",
       "      (beta_reparam): NonNegativeParametrizer(\n",
       "        (lower_bound): LowerBound()\n",
       "      )\n",
       "      (gamma_reparam): NonNegativeParametrizer(\n",
       "        (lower_bound): LowerBound()\n",
       "      )\n",
       "    )\n",
       "    (6): Conv2d(128, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "  )\n",
       "  (g_s): Sequential(\n",
       "    (0): ConvTranspose2d(192, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
       "    (1): GDN(\n",
       "      (beta_reparam): NonNegativeParametrizer(\n",
       "        (lower_bound): LowerBound()\n",
       "      )\n",
       "      (gamma_reparam): NonNegativeParametrizer(\n",
       "        (lower_bound): LowerBound()\n",
       "      )\n",
       "    )\n",
       "    (2): ConvTranspose2d(128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
       "    (3): GDN(\n",
       "      (beta_reparam): NonNegativeParametrizer(\n",
       "        (lower_bound): LowerBound()\n",
       "      )\n",
       "      (gamma_reparam): NonNegativeParametrizer(\n",
       "        (lower_bound): LowerBound()\n",
       "      )\n",
       "    )\n",
       "    (4): ConvTranspose2d(128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
       "    (5): GDN(\n",
       "      (beta_reparam): NonNegativeParametrizer(\n",
       "        (lower_bound): LowerBound()\n",
       "      )\n",
       "      (gamma_reparam): NonNegativeParametrizer(\n",
       "        (lower_bound): LowerBound()\n",
       "      )\n",
       "    )\n",
       "    (6): ConvTranspose2d(128, 3, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
       "  )\n",
       "  (h_a): Sequential(\n",
       "    (0): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (2): Conv2d(128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "    (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (4): Conv2d(128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "  )\n",
       "  (h_s): Sequential(\n",
       "    (0): ConvTranspose2d(128, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (2): ConvTranspose2d(192, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
       "    (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (4): Conv2d(288, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (gaussian_conditional): GaussianConditional(\n",
       "    (likelihood_lower_bound): LowerBound()\n",
       "    (lower_bound_scale): LowerBound()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net = mbt2018_mean(quality=1, pretrained=True).to(device)\n",
    "net.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Применение кодека mbt2018-mean к изображениям ( (H, W) = (512, 1024) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved frame_0021.png\n",
      "Processed and saved frame_0022.png\n",
      "Processed and saved frame_0023.png\n",
      "Processed and saved frame_0024.png\n",
      "Processed and saved frame_0025.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for filename in sorted(os.listdir(orig_resize_folder)):\n",
    "    \n",
    "    img_path = os.path.join(orig_resize_folder, filename)\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "    transform = transforms.ToTensor()\n",
    "    x = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out_net = net(x)\n",
    "        \n",
    "    out_img = out_net['x_hat'].clamp(0, 1).squeeze().cpu()\n",
    "    out_img_pil = transforms.ToPILImage()(out_img)\n",
    "    \n",
    "    output_path = os.path.join(reconstr_folder, f'reconstructed_{filename}')\n",
    "    out_img_pil.save(output_path)\n",
    "    \n",
    "    print(f'Processed and saved {filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sys.path.append(os.path.join(root_path,'RAFT'))\n",
    "sys.path.append(os.path.join(root_path,\"RAFT\\\\core\"))\n",
    "#sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from raft import RAFT\n",
    "from utils import flow_viz\n",
    "from utils.utils import InputPadder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Определение путей для сохранения визуализаций оптических потоков\n",
    "\n",
    "- **opt_flow_between_orig** - Оптические потоки между оригинальными кадрами.\n",
    "- **pt_flow_between_reconstr** - Оптические потоки между реконструированными кадрами (после применения модели mbt2018-mean).\n",
    "- **opt_flow_reconstr_orig** - Реконструкции оптических потоков между оригинальными кадрами (после применения модели mbt2018-mean).\n",
    "- **opt_flow_reconstr_reconstr** - Реконструкции оптических потоков между реконструированными кадрами (после применения модели mbt2018-mean).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_flow_between_orig = 'opt_flow\\\\between_orig'# тут просто оптический поток\n",
    "opt_flow_between_reconstr = 'opt_flow\\\\between_reconstr'# тут опт поток между реконстр кадрами\n",
    "opt_flow_reconstr_orig = 'opt_flow\\\\reconstr_b-n_orig'# тут реконструкци ориганльных оптических потоков\n",
    "opt_flow_reconstr_reconstr = 'opt_flow\\\\reconstr_b-n_reconstr'# тут реконструкция реконструированных оптических потоков\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вспомогательные функции для использования RAFT.\n",
    "За основу взят код из файла demo.py из репозитория RAFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(imfile):\n",
    "    img = np.array(Image.open(imfile)).astype(np.uint8)\n",
    "    img = torch.from_numpy(img).permute(2, 0, 1).float()\n",
    "    return img[None].to(device)\n",
    "\n",
    "def demo(args, input_folder, output_folder):\n",
    "    model = torch.nn.DataParallel(RAFT(args))\n",
    "    model.load_state_dict(torch.load(args.model))\n",
    "\n",
    "    model = model.module\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    #print(\"bbbb\")\n",
    "    with torch.no_grad():\n",
    "        images = glob.glob(os.path.join(input_folder, '*.png'))\n",
    "        #print(\"b\")\n",
    "        images = sorted(images)\n",
    "        for idx, (imfile1, imfile2) in enumerate(zip(images[:-1], images[1:])):\n",
    "            image1 = load_image(imfile1)\n",
    "            image2 = load_image(imfile2)\n",
    "            #print(\"k\")\n",
    "            padder = InputPadder(image1.shape)\n",
    "            image1, image2 = padder.pad(image1, image2)\n",
    "\n",
    "            flow_low, flow_up = model(image1, image2, iters=20, test_mode=True)\n",
    "           # viz(image1, flow_up)\n",
    "\n",
    "            opt_flow = flow_up[0].permute(1,2,0).cpu().numpy()\n",
    "            #print(opt_flow.shape)\n",
    "            \n",
    "            # map flow to rgb image\n",
    "            img_flo = flow_viz.flow_to_image(opt_flow)\n",
    "\n",
    "            #img_flo = np.concatenate([img, flo], axis=0)\n",
    "            #import matplotlib.pyplot as plt\n",
    "            #plt.imshow(img_flo / 255.0)\n",
    "            #plt.show()\n",
    "            #import matplotlib.pyplot as plt\n",
    "            #plt.imshow(img_flo / 255.0)\n",
    "            #plt.show()\n",
    "\n",
    "            output_filename = f'flow_{idx}-{idx+1}.png'\n",
    "            output_path = os.path.join(output_folder, output_filename)\n",
    "            \n",
    "            #cv2.imshow('image', img_flo[:, :, [2,1,0]]/255.0)\n",
    "            #cv2.waitKey()\n",
    "\n",
    "            cv2.imwrite(output_path, img_flo[:, :, [2,1,0]])\n",
    "            \n",
    "            #print('aaa')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вычисление оптических потоков между всеми кадрами (сначала между оригинальными, затем между реконструированными) и сохранение визуализаций в указанные директории."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "args1 = Namespace(\n",
    "    model='models/models/raft-things.pth',\n",
    "    path=None,\n",
    "    small=False,\n",
    "    mixed_precision=False,\n",
    "    alternate_corr=False\n",
    "    )\n",
    "demo(args1, orig_resize_folder, opt_flow_between_orig)\n",
    "demo(args1, reconstr_folder, opt_flow_between_reconstr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Применение кодека mbt2018-mean к визуализациям (к изображениям) оптического потока и сохранение получившихся изображений в указанные директории."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_bpp_1 = []\n",
    "#list_x_hat_1 =[]\n",
    "for filename in sorted(os.listdir(opt_flow_between_orig)):\n",
    "    \n",
    "    img_path = os.path.join(opt_flow_between_orig, filename)\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "    transform = transforms.ToTensor()\n",
    "    x = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out_net = net(x)\n",
    "  \n",
    "    #list_bpp_1.append(compute_bpp(out_net))\n",
    "\n",
    "    out_img = out_net['x_hat'].clamp(0, 1).squeeze().cpu()\n",
    "    out_img_pil = transforms.ToPILImage()(out_img)\n",
    "\n",
    "    #list_x_hat_1.append(out_net['x_hat'])\n",
    "    \n",
    "    output_path = os.path.join(opt_flow_reconstr_orig, f'reconstr_orig_{filename}')\n",
    "    out_img_pil.save(output_path)\n",
    "    #print(f'Processed and saved {filename}')\n",
    "\n",
    "#print(list_x_hat_1)\n",
    "#formatted_bpp_list = [f\"{bpp:.3f}\" for bpp in list_bpp_1]\n",
    "#print(formatted_bpp_list)    \n",
    "    \n",
    "#print(likelihoods_list_1)\n",
    "#list_bpp_2 = []\n",
    "#list_x_hat_2 = []\n",
    "for filename in sorted(os.listdir(opt_flow_between_reconstr)):\n",
    "    \n",
    "    img_path = os.path.join(opt_flow_between_reconstr, filename)\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "    transform = transforms.ToTensor()\n",
    "    x = transform(img).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        out_net = net(x)\n",
    "    #list_bpp_2.append(compute_bpp(out_net))\n",
    "    #list_x_hat_2.append(out_net['x_hat'])\n",
    "\n",
    "    out_img = out_net['x_hat'].clamp(0, 1).squeeze().cpu()\n",
    "    out_img_pil = transforms.ToPILImage()(out_img)\n",
    "    \n",
    "    output_path = os.path.join(opt_flow_reconstr_reconstr, f'reconstr_reconstr_{filename}')\n",
    "    out_img_pil.save(output_path)\n",
    "    \n",
    "    #print(f'Processed and saved {filename}')\n",
    "#formatted_bpp_list = [f\"{bpp:.3f}\" for bpp in list_bpp_2]\n",
    "#print(formatted_bpp_list)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
